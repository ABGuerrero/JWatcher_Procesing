{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c0dc85-18d3-41cf-950e-0986222f60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25180502-04bf-4ea9-8a36-7843b16cf87e",
   "metadata": {},
   "source": [
    "### Function that will normalize the way the date is written on the files\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ba2ac3-d844-4296-b342-cbd32718e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_date(date_str):\n",
    "    from datetime import datetime\n",
    "    try:\n",
    "        # Attempt to parse the date in various formats\n",
    "        date_formats = ['_%Y_%m_%d', '_%y_%m_%d', '_%y_%m_%d']\n",
    "        for fmt in date_formats:\n",
    "            try:\n",
    "                date_obj = datetime.strptime(date_str, fmt)\n",
    "                return date_obj.strftime('%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                pass  # Continue to next format\n",
    "        # If none of the formats match, return None\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while parsing date: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9ca66-a4e8-41c0-9bdf-05c7fa74e3bc",
   "metadata": {},
   "source": [
    "### Function that will read the .dat files\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b295e26a-296c-4687-ae3c-0bf9e7171487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dat_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Find the index of the line that says '#BEGIN DATA'\n",
    "    data_start_index = next(i for i, line in enumerate(lines) if '#BEGIN DATA' in line)\n",
    "    \n",
    "    # Initialize lists to store trial data\n",
    "    start_zones = []\n",
    "    end_zones = []\n",
    "    stops = []\n",
    "    prods = []\n",
    "    \n",
    "    # Process lines after '#BEGIN DATA'\n",
    "    i = data_start_index + 1\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip().split(',')\n",
    "        if len(line) < 2:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Parse the zone and value\n",
    "        zone = line[1].strip()\n",
    "        \n",
    "        if zone == 'EOF':\n",
    "            break\n",
    "        elif zone == 'n':\n",
    "            # Skip trial if it contains 'n'\n",
    "            i += 1\n",
    "            continue\n",
    "        elif zone == 'f':\n",
    "            # Confirm end of trial, move to next trial\n",
    "            i += 1\n",
    "            continue\n",
    "        elif zone.isdigit():\n",
    "            zone = int(zone)\n",
    "            if len(start_zones) == len(end_zones):\n",
    "                start_zones.append(zone)\n",
    "                stops.append(0)\n",
    "                prods.append(0)\n",
    "            else:\n",
    "                end_zones.append(zone)\n",
    "        elif zone == 's':\n",
    "            stops[-1] += 1\n",
    "        elif zone == 'p':\n",
    "            prods[-1] += 1\n",
    "        i += 1\n",
    "    \n",
    "    # Create a DataFrame from the collected data\n",
    "    trial_data = pd.DataFrame({\n",
    "        'Start_Zone': start_zones,\n",
    "        'End_Zone': end_zones,\n",
    "        'Stops': stops,\n",
    "        'Prods': prods\n",
    "    })\n",
    "    \n",
    "    return trial_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0f02a-62f6-41df-b2d8-a29b6ad7a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(read_dat_file(\".dat file_path\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55745caa-8168-4eed-84d1-3b0761483bd8",
   "metadata": {},
   "source": [
    "## Here we will input the rewarded zone.\r\n",
    "### With the function ErrorScore we will determine the difference between the end zone (second in each pair) and the Rewarded Zone (RewZone)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5296df-aa3f-44f7-8d59-ecbaff7f1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "RewZone = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ca1d6a-5b5e-4a7d-98fe-fbcf308421c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ErrorScore(data_path, RewZone):\n",
    "    errors = []\n",
    "    trial_data = read_dat_file(data_path)\n",
    "    for index, row in trial_data.iterrows():\n",
    "        start_zone = row['Start_Zone']\n",
    "        end_zone = row['End_Zone']\n",
    "        \n",
    "        if end_zone == RewZone:\n",
    "            error = 0\n",
    "        else:\n",
    "            error = (end_zone - RewZone) % 8\n",
    "            if error > 4:\n",
    "                error -= 8\n",
    "        \n",
    "        errors.append(error)\n",
    "    \n",
    "    trial_data['Error'] = errors\n",
    "    return trial_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d29f5-462c-4e35-b730-6a465e9597b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorScoreData = ErrorScore(\".dat file_path\", RewZone)\n",
    "print(ErrorScoreData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890216a3-e016-4b93-9783-8b79d7b72915",
   "metadata": {},
   "source": [
    "### Iteration function\r\n",
    "#### This function will iterate through a folder of your choice and look for .dat files whose name starts with the string you also input, which should be the ID of the animal. \r\n",
    "#### The function will create txt files that will have the vector created by ErrorScore\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05eb5de6-3c7b-4227-bbee-c8e27cc9cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_in_folder(folder_path, RewZone):\n",
    "    file_prefix = 'RMB'\n",
    "    # Find all .dat files starting with the given prefix in the specified folder\n",
    "    search_pattern = os.path.join(folder_path, f'{file_prefix}*.dat')\n",
    "    dat_files = glob.glob(search_pattern)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for dat_file in dat_files:\n",
    "        # Read data from the .dat file\n",
    "        trial_data = read_dat_file(dat_file)\n",
    "        \n",
    "        if not trial_data.empty:\n",
    "            # Calculate error scores and create DataFrame\n",
    "            df = ErrorScore(dat_file, RewZone)\n",
    "            \n",
    "            # Extract the date from the filename\n",
    "            base_name = os.path.basename(dat_file)\n",
    "            date_part = base_name.replace(file_prefix, '').replace('.dat', '')\n",
    "            normalized_day = normalize_date(date_part)\n",
    "            # Add Date column to DataFrame\n",
    "            df.insert(0, 'Date', normalized_day)\n",
    "            \n",
    "            # Append DataFrame to all_results\n",
    "            all_results.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    result_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "    # Add Date and Trial indices\n",
    "    result_df['Date_Index'] = result_df.groupby('Date').ngroup() + 1\n",
    "    result_df['Trial_Index'] = result_df.groupby('Date').cumcount() + 1\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_filename = os.path.join(folder_path, f'MEA_Results_{os.path.basename(folder_path)}.csv')\n",
    "    result_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Results saved to {output_filename}\")\n",
    "    \n",
    "    classify_errors(output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b63646-faf9-4f0a-8ccb-1eb6f7ba03e4",
   "metadata": {},
   "source": [
    "### Use example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb330a5b-5d7a-45bb-84c4-9339efa863ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'X:\\\\MATT_SCORING'  # Replace with the path to your folder\n",
    "file_prefix = 'RMB4'  # Example file prefix to look for\n",
    "RewZone = 5  # Example value for RewZone\n",
    "process_files_in_folder(folder_path, file_prefix, RewZone)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ed2ba-972e-4bf0-b28a-ecfbed9238a1",
   "metadata": {},
   "source": [
    "## Combine CSV files from subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1ff138-6fbe-4167-8fed-ba92ddf97d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to X:/MATT_SCORING\\combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "def combine_csv_files(root_folder):\n",
    "    all_data = []\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                animal_id = os.path.basename(subdir).split('_')[0]\n",
    "                df['Animal_ID'] = animal_id\n",
    "                all_data.append(df)\n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        combined_filename = os.path.join(root_folder, 'combined_data.csv')\n",
    "        combined_df.to_csv(combined_filename, index=False)\n",
    "        print(f\"Combined data saved to {combined_filename}\")\n",
    "    else:\n",
    "        print(\"No CSV files found in the specified folder.\")\n",
    "\n",
    "root_folder = 'X:/MATT_SCORING'  # Replace with the root path to your folder containing all the CSVs\n",
    "combine_csv_files(root_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4158008f-3d1e-4558-a49e-1d6a81e4fb38",
   "metadata": {},
   "source": [
    "## Fit linear model to determine if there are differences between groups  types of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12393e-4d21-4a5c-87b0-1933c28788b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear mixed model\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load the combined dataset\n",
    "combined_data = pd.read_csv(\"X:/MATT_SCORING/combined_data.csv\")\n",
    "\n",
    "# Convert Animal_ID, Age, and Group to categorical data type\n",
    "combined_data['Animal_ID'] = combined_data['Animal_ID'].astype('category')\n",
    "combined_data['Age'] = combined_data['Age'].astype('category')\n",
    "combined_data['Group'] = combined_data['Group'].astype('category')\n",
    "\n",
    "# Define the formula for the linear mixed model\n",
    "formula = 'Error ~ C(Age) * C(Group)'\n",
    "\n",
    "# Fit the linear mixed model\n",
    "model = smf.mixedlm(formula, combined_data, groups=combined_data['Animal_ID'])\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
